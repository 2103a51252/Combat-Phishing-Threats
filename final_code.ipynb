{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ritw_xLXUuY",
        "outputId": "e54ba14c-ade3-432a-e0fb-a7356e8c1ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Ensemble (Random Forest + KNN)\n",
            "[[988  26]\n",
            " [ 73 913]]\n",
            "Accuracy: 0.9505\n",
            "Precision: 0.9723\n",
            "Recall: 0.9260\n",
            "F1 Score: 0.9486\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      1014\n",
            "           1       0.97      0.93      0.95       986\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.95      0.95      0.95      2000\n",
            "weighted avg       0.95      0.95      0.95      2000\n",
            "\n",
            "Model: Ensemble (Random Forest + KNN + Decision Tree)\n",
            "[[994  20]\n",
            " [ 77 909]]\n",
            "Accuracy: 0.9515\n",
            "Precision: 0.9785\n",
            "Recall: 0.9219\n",
            "F1 Score: 0.9493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      1014\n",
            "           1       0.98      0.92      0.95       986\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.95      0.95      0.95      2000\n",
            "weighted avg       0.95      0.95      0.95      2000\n",
            "\n",
            "Model: Ensemble (Random Forest + KNN + Naive Bayes)\n",
            "[[1006    8]\n",
            " [ 111  875]]\n",
            "Accuracy: 0.9405\n",
            "Precision: 0.9909\n",
            "Recall: 0.8874\n",
            "F1 Score: 0.9363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94      1014\n",
            "           1       0.99      0.89      0.94       986\n",
            "\n",
            "    accuracy                           0.94      2000\n",
            "   macro avg       0.95      0.94      0.94      2000\n",
            "weighted avg       0.95      0.94      0.94      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset (replace with your actual dataset)\n",
        "data = pd.read_csv(r'/Phishing2.csv')\n",
        "\n",
        "# Feature extraction from URLs\n",
        "def extract_features(url):\n",
        "    features = {}\n",
        "    features['url_length'] = len(url)\n",
        "    features['num_special_chars'] = sum([1 for char in url if char in ['?', '&', '=', '-', '_', '.']])\n",
        "    features['has_ip'] = int(any(char.isdigit() for char in url.split('/')))\n",
        "    features['num_subdomains'] = url.count('.') - 1\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction\n",
        "url_features = data['url'].apply(lambda x: pd.Series(extract_features(x)))\n",
        "\n",
        "# Combine the extracted features with the original data\n",
        "data = pd.concat([data.drop('url', axis=1), url_features], axis=1)\n",
        "\n",
        "# Encode the labels if they are categorical\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data['label'])\n",
        "\n",
        "# Define features and labels\n",
        "X = data.drop('label', axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize models\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Combine models using Voting Classifier\n",
        "voting_clf_2 = VotingClassifier(estimators=[\n",
        "    ('Random Forest', rf),\n",
        "    ('KNN', knn)\n",
        "], voting='soft')  # Using 'soft' voting for probability averaging\n",
        "\n",
        "voting_clf_3 = VotingClassifier(estimators=[\n",
        "    ('Random Forest', rf),\n",
        "    ('KNN', knn),\n",
        "    ('Decision Tree', dt)\n",
        "], voting='soft')\n",
        "\n",
        "voting_clf_4 = VotingClassifier(estimators=[\n",
        "    ('Random Forest', rf),\n",
        "    ('KNN', knn),\n",
        "    ('Naive Bayes', nb)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the combined models\n",
        "voting_clf_2.fit(X_train, y_train)\n",
        "voting_clf_3.fit(X_train, y_train)\n",
        "voting_clf_4.fit(X_train, y_train)\n",
        "\n",
        "# Predict for each combination\n",
        "y_pred_voting_2 = voting_clf_2.predict(X_test)\n",
        "y_pred_voting_3 = voting_clf_3.predict(X_test)\n",
        "y_pred_voting_4 = voting_clf_4.predict(X_test)\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(model_name, y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluate Voting Classifiers with 2, 3, and 4 models\n",
        "evaluate_model('Ensemble (Random Forest + KNN)', y_test, y_pred_voting_2)\n",
        "evaluate_model('Ensemble (Random Forest + KNN + Decision Tree)', y_test, y_pred_voting_3)\n",
        "evaluate_model('Ensemble (Random Forest + KNN + Naive Bayes)', y_test, y_pred_voting_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a table with the provided results\n",
        "def display_results():\n",
        "    # Results for Stacking and XGBoost models\n",
        "    results_data = {\n",
        "        'Model': ['Stacking (Random Forest + XGBoost + KNN)', 'XGBoost'],\n",
        "        'Accuracy': [0.9565, 0.9505],\n",
        "        'Precision': [0.9668, 0.9733],\n",
        "        'Recall': [0.9442, 0.9249],\n",
        "        'F1 Score': [0.9554, 0.9485]\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame\n",
        "    results_df = pd.DataFrame(results_data)\n",
        "\n",
        "    # Print the results in tabular form\n",
        "    print(results_df)\n",
        "\n",
        "# Call the function to display the table\n",
        "display_results()\n"
      ],
      "metadata": {
        "id": "Zlj7PQ9oNlz8",
        "outputId": "f34b36e6-e431-4f18-a645-51d55706fba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Model  Accuracy  Precision  Recall  \\\n",
            "0  Stacking (Random Forest + XGBoost + KNN)    0.9565     0.9668  0.9442   \n",
            "1                                   XGBoost    0.9505     0.9733  0.9249   \n",
            "\n",
            "   F1 Score  \n",
            "0    0.9554  \n",
            "1    0.9485  \n"
          ]
        }
      ]
    }
  ]
}